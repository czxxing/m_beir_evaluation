#!/usr/bin/env python3
"""
ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡ŒM-BEIRè¯„ä¼°
"""

import os
import sys
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.dataloader import MBEIRDataLoader, create_sample_dataset
from src.models.retrieval_models import LocalModel, get_retrieval_model
from src.evaluation.metrics import calculate_metrics_batch


def download_model_to_local():
    """å°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ç›®å½•çš„ç¤ºä¾‹å‡½æ•°"""
    from sentence_transformers import SentenceTransformer
    
    # æœ¬åœ°æ¨¡å‹ç›®å½• - ä½¿ç”¨æ›´å°çš„æ¨¡å‹
    local_model_dir = Path("../models/all-MiniLM-L6-v2")
    local_model_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç›®å½•: {local_model_dir}")
    print("ä½¿ç”¨æ›´å°çš„æ¨¡å‹: all-MiniLM-L6-v2 (çº¦80MB)")
    
    # ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç›®å½• - ä½¿ç”¨æ›´å°çš„æ¨¡å‹
    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
    model.save(str(local_model_dir))
    
    print("æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
    return str(local_model_dir)


def load_local_model_example():
    """åŠ è½½æœ¬åœ°æ¨¡å‹çš„ç¤ºä¾‹"""
    print("=" * 60)
    print("æœ¬åœ°æ¨¡å‹åŠ è½½ç¤ºä¾‹")
    print("=" * 60)
    
    # æ–¹æ³•1ï¼šç›´æ¥ä½¿ç”¨LocalModelç±»
    print("\\næ–¹æ³•1ï¼šç›´æ¥ä½¿ç”¨LocalModelç±»")
    print("-" * 40)
    
    # å‡è®¾æ¨¡å‹å·²ç»ä¸‹è½½åˆ°æœ¬åœ°
    model_path = "../models/all-MiniLM-L6-v2"
    
    if not os.path.exists(model_path):
        print("æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œå…ˆä¸‹è½½æ¨¡å‹...")
        model_path = download_model_to_local()
    
    # åˆ›å»ºæœ¬åœ°æ¨¡å‹å®ä¾‹
    local_model = LocalModel(
        model_path=model_path,
        device="cpu",
        model_type="sentence_transformer"
    )
    
    # æµ‹è¯•ç¼–ç 
    test_texts = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬", "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"]
    embeddings = local_model.encode_texts(test_texts)
    print(f"ç¼–ç æµ‹è¯•æˆåŠŸï¼åµŒå…¥ç»´åº¦: {embeddings.shape}")
    
    # æ–¹æ³•2ï¼šä½¿ç”¨é…ç½®å­—å…¸å’Œå·¥å‚å‡½æ•°
    print("\\næ–¹æ³•2ï¼šä½¿ç”¨é…ç½®å­—å…¸å’Œå·¥å‚å‡½æ•°")
    print("-" * 40)
    
    model_config = {
        'name': 'local-minilm-model',
        'type': 'local',
        'path': model_path,
        'local_model_type': 'sentence_transformer',
        'device': 'cpu'
    }
    
    model_from_factory = get_retrieval_model(model_config)
    
    # æµ‹è¯•ç¼–ç 
    embeddings2 = model_from_factory.encode_texts(test_texts)
    print(f"å·¥å‚æ–¹æ³•ç¼–ç æµ‹è¯•æˆåŠŸï¼åµŒå…¥ç»´åº¦: {embeddings2.shape}")
    
    return local_model


def evaluate_with_local_model():
    """ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œè¯„ä¼°çš„å®Œæ•´ç¤ºä¾‹"""
    print("\\n" + "=" * 60)
    print("ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œè¯„ä¼°")
    print("=" * 60)
    
    # 1. å‡†å¤‡æ•°æ®
    data_dir = Path("../data")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    dataset_dir = data_dir / "sample"
    dataset_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
    create_sample_dataset(dataset_dir)
    
    # 2. åŠ è½½æ•°æ®
    data_loader = MBEIRDataLoader(data_dir)
    dataset = data_loader.load_dataset("sample", "sample")
    
    # æå–æ–‡æœ¬å†…å®¹
    queries = [doc['text'] for doc in dataset['queries'].values()]
    corpus = [doc['text'] for doc in dataset['corpus'].values()]
    
    # åˆ›å»ºqrels
    qrels = {}
    for query_id in dataset['queries'].keys():
        qrels[query_id] = dataset['qrels'].get(query_id, [])
    
    print(f"åŠ è½½æ•°æ®: {len(queries)} ä¸ªæŸ¥è¯¢, {len(corpus)} ä¸ªæ–‡æ¡£")
    
    # 3. åŠ è½½æœ¬åœ°æ¨¡å‹
    model_path = "../models/all-MiniLM-L6-v2"
    if not os.path.exists(model_path):
        print("æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œå…ˆä¸‹è½½æ¨¡å‹...")
        model_path = download_model_to_local()
    
    model_config = {
        'name': 'local-minilm-model',
        'type': 'local',
        'path': model_path,
        'local_model_type': 'sentence_transformer',
        'device': 'cpu'
    }
    
    model = get_retrieval_model(model_config)
    
    # 4. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    metrics_to_calculate = ['ndcg@3', 'recall@3', 'map']
    
    print("\\nè®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    results = calculate_metrics_batch(
        queries, 
        corpus, 
        qrels, 
        model, 
        metrics_to_calculate, 
        k=3
    )
    
    # 5. æ˜¾ç¤ºç»“æœ
    print("\\nè¯„ä¼°ç»“æœ:")
    print("-" * 30)
    for metric, score in results.items():
        print(f"{metric}: {score:.4f}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    print("M-BEIR æœ¬åœ°æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹")
    
    try:
        # ç¤ºä¾‹1ï¼šåŠ è½½æœ¬åœ°æ¨¡å‹
        model = load_local_model_example()
        
        # ç¤ºä¾‹2ï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œè¯„ä¼°
        results = evaluate_with_local_model()
        
        print("\\n" + "ğŸ‰ ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("\\nä½¿ç”¨è¯´æ˜:")
        print("1. å°†é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ç›®å½•")
        print("2. ä½¿ç”¨LocalModelç±»æˆ–é…ç½®å­—å…¸åŠ è½½æ¨¡å‹")
        print("3. è¿›è¡Œæ–‡æœ¬ç¼–ç å’Œè¯„ä¼°")
        
    except Exception as e:
        print(f"\\nâŒ è¿è¡Œå‡ºé”™: {e}")
        print("\\nå¯èƒ½çš„åŸå› :")
        print("1. æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        print("2. æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
        print("3. ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…")


if __name__ == "__main__":
    main()